{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d2401-ee15-4a73-879b-9eafa0f53b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for testing\n",
    "# This code cell will be replaced by Times Square\n",
    "# /sdf/home/h/huanlin/shared_campaigns_LSST/DM-53195/submit/LSSTCam/runs/DRP/20250421_20250921/d_2025_11_10/DM-53195\n",
    "#submitHead = \"/sdf/data/rubin/shared/campaigns/LSSTCam-Nightly-Validation-CC/\"\n",
    "#tasksHead = \"DM-50157_20250609/submit/LSSTCam/runs/nightlyValidation/20250609/d_2025_06_09/DM-50157\"\n",
    "#submitHead = \"/sdf/home/h/huanlin/shared_campaigns_LSST/\"\n",
    "submitHead = \"/home/h/huanlin/shared_campaigns_LSST/\"\n",
    "tasksHead = \"DM-53195/submit/LSSTCam/runs/DRP/20250421_20250921/d_2025_11_10/DM-53195/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------\n",
    "# failureLister - get list of failed task jobs and show the errors\n",
    "# author: Homer Neal\n",
    "# ---------------------------------------------------------------------------------------\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import math\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# ---- types\n",
    "#analyzeSingleVisitStar\n",
    "#analyzeSingleVisitStarAssociation\n",
    "#analyzeSingleVisitStarAstrometricRefMatch\n",
    "#analyzeSingleVisitStarPhotometricRefMatch\n",
    "#associateIsolatedStar\n",
    "#coadd\n",
    "#consolidateHealSparsePropertyMaps\n",
    "#consolidateSingleVisitStar\n",
    "#consolidateVisitSummary\n",
    "#makeAnalysisSingleVisitStarAstrometricRefMatch\n",
    "#makeAnalysisSingleVisitStarPhotometricRefMatch\n",
    "#makeHealSparsePropertyMaps\n",
    "#makeWarpTract\n",
    "#selectDeepCoaddVisits\n",
    "\n",
    "jobs = [\"generateEphemerides\",\"fgcmFitCycle\",\"analyzeSingleVisitStar\",\"analyzeSingleVisitStarAssociation\",\"analyzeSingleVisitStarAstrometricRefMatch\",\"analyzeSingleVisitStarPhotometricRefMatch\",\"associateIsolatedStar\",\"coadd\",\"consolidateHealSparsePropertyMaps\",\"consolidateSingleVisitStar\",\"consolidateVisitSummary\",\"finalJob\",\"makeAnalysisSingleVisitStarAssociationMetricTable\",\"makeAnalysisSingleVisitStarAssociationWholeSkyPlot\",\"makeAnalysisSingleVisitStarAstrometricRefMatch\",\"makeAnalysisSingleVisitStarPhotometricRefMatch\",\"makeHealSparsePropertyMaps\",\"makeInitialVisitDetectorTable\",\"makeInitialVisitTable\",\"makeWarpTract\",\"pipetaskInit\",\"plotPropertyMapSurvey\",\"selectDeepCoaddVisits\",\"step1detector\"]\n",
    "#jobs = [\"analyzeSingleVisitStarAssociation\"]\n",
    "#jobs = [\"step1detector\"]\n",
    "df = pd.DataFrame(columns=['job name','errors','file'])\n",
    "\n",
    "def dumpError(flin):\n",
    "    err = \"\"\n",
    "    fpin = open(flin)\n",
    "    for ln in fpin:\n",
    "        if \"ERROR\" in ln.upper() :\n",
    "            err = ln\n",
    "            break\n",
    "    return err\n",
    "\n",
    "# tasksHead = \"LSSTCam/runs/nightlyValidation/20250530/d_2025_05_30/DM-50157/\"\n",
    "# tasksHead = \"DM-50157_20250607/submit/LSSTCam/runs/nightlyValidation/20250607/d_2025_06_08/DM-50157/\"\n",
    "\n",
    "leadPath = submitHead+tasksHead\n",
    "os.chdir(leadPath)\n",
    "# nodeStatFile=sys.argv[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nodeStatFile in glob.glob(\"*/*.node_status\"):\n",
    "#nodeStatFile = submitHead+tasksHead+\"20250531T113935Z/LSSTCam_runs_nightlyValidation_20250530_d_2025_05_30_DM-50157_20250531T113935Z.node_status\"\n",
    "#nodeStatFile = input(\"Path of node status file = \")\n",
    "#    ./20250611T154923Z/jobs/analyzeSingleVisitStar/22e500cc-c984-400a-be69-d182b405bd9d_analyzeSingleVisitStar_2025060900506_.17979981.err\n",
    "#      Type = \"NodeStatus\";\n",
    "#  Node = \"22e500cc-c984-400a-be69-d182b405bd9d_analyzeSingleVisitStar_2025060900506_\";\n",
    "#  NodeStatus = 5; /* \"STATUS_DONE\" */\n",
    "\n",
    "#    ./20250611T154923Z/jobs/analyzeSingleVisitStarAssociation/040f8daf-bfbd-4574-ba7f-02219bc3fb41_analyzeSingleVisitStarAssociation_7041_.18061387.err\n",
    "    taskID = nodeStatFile.split(\"/\")[0]\n",
    "    print(\"task = \"+taskID+\" | node_status file = \"+nodeStatFile)\n",
    "    fp = open(nodeStatFile)\n",
    "    nextline = False\n",
    "    for ln in fp:\n",
    "        if (\"Type\" in ln and \"NodeStatus\" in ln):\n",
    "    #        print(ln)\n",
    "            for ln2 in fp:\n",
    "                if (\"]\" in ln2):\n",
    "                    break\n",
    "                #print(ln2.strip().split()[0])\n",
    "                if (ln2.strip().split()[0] == \"Node\"):\n",
    "                    element = ln2.strip().split()[2].strip(';').strip('\"')\n",
    "#                    print(\"element = \"+element)\n",
    "                if (ln2.strip().split()[0] == \"NodeStatus\"):\n",
    "                    if (\"ERROR\" in ln2):\n",
    "                        element_pieces = element.split(\"_\")\n",
    "                        element_2_pieces = element.split(\"-\")\n",
    "                        secondElement = \"\"\n",
    "                        try:\n",
    "                            secondElement = element_pieces[1]\n",
    "                            lower_path = \"\"\n",
    "                            if len(element_pieces)>2 :\n",
    "                                for ielem in element_pieces[2:] :\n",
    "                                    lower_path = lower_path + \"/\" + ielem\n",
    "#                            print(\"lower_path = \"+lower_path+\" len = \"+str(len(lower_path)))\n",
    "#                            secondElement = element_2_pieces[5]\n",
    "                        except:\n",
    "                            pass\n",
    "                        flerr = \"\"\n",
    "                        for jb in jobs:\n",
    "#                            print(\"jb = \"+jb+\" | element_pieces[0] = \"+element_pieces[0]+\" | secondElement = \"+secondElement)\n",
    "#                            print(\"step1\")\n",
    "                            if jb in element_pieces[0] or nextline:\n",
    "#                                print(\"trying in pieces[0]\")\n",
    "                                try:\n",
    "#                                    print(\"path = \"+taskID+\"/jobs/\"+jb+\"/\"+element_pieces[1]+\"/\"+jb+\"_\"+element_pieces[1]+\"_\"+element_pieces[2]+\".*.*\")\n",
    "                                    try:\n",
    "#                                        print(\"try1\")\n",
    "                                        try:\n",
    "#                                            print(\"1\")\n",
    "                                            for flerr in glob.glob(taskID+\"/jobs/\"+jb+\"/\"+element_pieces[1]+\"/\"+jb+\"_\"+element_pieces[1]+\"_\"+element_pieces[2]+\".*.*\"):\n",
    "                                                print(\"flerr = \"+flerr)\n",
    "                                                try:\n",
    "                                                    new_row = pd.DataFrame({\"job name\": [element_pieces[0]], \"errors\":[dumpError(flerr)], \"file\":[leadPath+flerr]})\n",
    "                                                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "#                                                    print(\"success on try1\")\n",
    "                                                except:\n",
    "                                                    pass\n",
    "#                                            print(\"2\")\n",
    "                                        except:\n",
    "                                            pass\n",
    "                                    \n",
    "#                                        print(\"try2: \"+taskID+\"/jobs/\"+jb+\"/\"+jb+\"_\"+element_pieces[1]+\"_\"+element_pieces[2]+\".*.*\"+\" | element = \"+element)\n",
    "                                        try:\n",
    "                                            for flerr in glob.glob(taskID+\"/jobs/\"+jb+\"/\"+jb+\"_\"+element_pieces[1]+\"_\"+element_pieces[2]+\".*.*\"):\n",
    "#                                                print(\"flerr = \"+flerr)\n",
    "                                                try:\n",
    "                                                    new_row = pd.DataFrame({\"job name\": [element_pieces[0]], \"errors\":[dumpError(flerr)], \"file\":[leadPath+flerr]})\n",
    "                                                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "#                                                    print(\"success on try2\")\n",
    "                                                except:\n",
    "                                                    pass\n",
    "                                        except:\n",
    "                                            pass\n",
    "                                    except:\n",
    "                                        pass\n",
    "                                except:\n",
    "                                    pass\n",
    "#                            print(\"step2\")\n",
    "                            if jb==secondElement or nextline:\n",
    "#                                print(\"jb = \"+jb)\n",
    "                                try:\n",
    "                                    if len(lower_path)<1 :\n",
    "                                        flerr = glob.glob(taskID+\"/jobs/\"+jb+\"/\"+element+\"*.err\")[0]\n",
    "                                    else:\n",
    "#                                        print(\"trying - \"+\"*/jobs/\"+jb+lower_path+element+\"*.*\")\n",
    "                                        new_row = None\n",
    "                                        for flerr in glob.glob(taskID+\"/jobs/\"+jb+lower_path+element+\"*.*\"):\n",
    "#                                            print(\"flerr = \"+flerr)\n",
    "                                            try:\n",
    "                                                the_error = dumpError(flerr)\n",
    "                                                if len(the_error) > 0 :\n",
    "                                                    new_row = pd.DataFrame({\"job name\": [secondElement], \"errors\":[dumpError(flerr)], \"file\":[leadPath+flerr]})\n",
    "                                                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "                                except:\n",
    "                                    pass\n",
    "#                            print(element_pieces[1]+\"/\"+element_pieces[2])\n",
    "#                            print(\"*/jobs/step1detector/\"+element_pieces[1]+\"/step1detector_\"+element_pieces[1]+\"_\"+element_pieces[2]+\".*.err\")\n",
    "                        \n",
    "##                                print(element + \": stat = \" + ln2.strip().split()[4].strip('\"') + \" file = \" + flerr )\n",
    "##                                print(dumpError(flerr))\n",
    "                        if not nextline:\n",
    "                            nextline = False # deactivating\n",
    "                        else:\n",
    "                            nextline = False\n",
    "#    print(df)\n",
    "#    print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "    display(HTML(df.to_html()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607b31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
